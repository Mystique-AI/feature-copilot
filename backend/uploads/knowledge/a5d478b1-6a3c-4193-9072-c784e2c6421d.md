# Mystique Graph Service

## Overview
A FastAPI-based service that executes LangGraph-based AI agent workflows. This is the core execution engine for running AI teams, managing chat services, and orchestrating background tasks.

## Application Type
- **Type**: Backend API Service (AI Orchestration)
- **Framework**: FastAPI with LangGraph
- **Database**: PostgreSQL (with checkpointing)
- **Message Queue**: RabbitMQ / Google Cloud Tasks

## Features

### Graph Execution (`/graph_request`)
| Endpoint | Method | Feature | Description | Role |
|----------|--------|---------|-------------|------|
| `/execute` | POST | Execute Graph | Execute a LangGraph workflow asynchronously | System |

### Background Tasks (`/background_task`)
| Endpoint | Method | Feature | Description | Role |
|----------|--------|---------|-------------|------|
| Cloud Tasks endpoints | - | Google Cloud Tasks | Handle background job execution | System |

### RabbitMQ Tasks (`/rmq_background_task`)
| Endpoint | Method | Feature | Description | Role |
|----------|--------|---------|-------------|------|
| RabbitMQ endpoints | - | Message Queue | Handle RabbitMQ-based task execution | System |

## Core Services

### Chat Service (`chat_service.py`)
- Message creation and routing
- Session management
- Response handling
- Async message processing

### Request Service (`request_service.py`)
- Request management for graph execution
- State persistence
- Error handling

### Prompt Service (`prompt_service.py`)
- **Prompt Vault Helper**: Dynamic prompt management
- Get/set prompts for teams
- Version control for prompts

### Team Service (`teams_service.py`)
- Team configuration access
- Graph ID resolution

### Dataroom Services
- `dataroom_service.py`: Knowledge base management
- `dataroom_files_service.py`: File operations within datarooms

### Integration Service (`integrations_service.py`)
- External integration management
- Credential handling

## Technical Architecture

### Graph Execution Flow
1. Request received via `/graph_request/execute`
2. GraphRunner loads appropriate team graph
3. State initialized with injected services
4. LangGraph workflow executed with checkpointing
5. Results returned or streamed via alerts

### Injected Services (State)
```python
state = {
    "litellm_obj": LlmClient,      # LLM API client
    "alert_store_obj": AlertStore,  # Real-time notifications
    "object_storage": StorageClient, # File storage (S3)
    "rag_service": RAGService,      # RAG operations
    "team_id": str,                 # Team identifier
    "session_id": str               # Conversation session
}
```

### Background Processing
- Google Cloud Tasks for GCP deployments
- RabbitMQ for self-hosted deployments
- Async execution with state persistence

## Integration Points
- LangGraph teams (via GraphFactory)
- PostgreSQL for state checkpointing
- RabbitMQ / Google Pub/Sub for messaging
- Object storage (S3/MinIO)
